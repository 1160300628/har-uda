{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGjxwdci2hoW"
   },
   "source": [
    "# har-classifiers\n",
    "\n",
    "unsupervised cross subjects domain adaptation for human activity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AuwMV5SV3EgV",
    "outputId": "ec6bde6d-3525-4027-f282-c5776fbaf0fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Lambda\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import gc\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "FrohmyO3ikRc",
    "outputId": "8bf92f97-efd8-467a-f02e-cab9cb0968c1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_q3fSn-o3LYr"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We use HCI HAR dataset. For more information about this dataset, you can click [Human Activity Recognition Using Smartphones Data Set, UCI Machine Learning Repository](https://link.springer.com/chapter/10.1007/978-3-642-35395-6_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "P7dgi47-3KtD",
    "outputId": "eea5ecb3-332c-4a3d-9337-b93d387b5156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
      "61005824/60999314 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip'\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file('HARDataset.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'UCI HAR Dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_CZCDZ-3xey"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAQqeB0c3v8z"
   },
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    '''\n",
    "    load a single file as a numpy array\n",
    "    '''\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "\n",
    "def load_group(filenames):\n",
    "    '''\n",
    "    load a list of files into a 3D array of [samples, timesteps, features]\n",
    "    '''\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(name)\n",
    "        loaded.append(data)\n",
    "    loaded = np.dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "\n",
    "def load_dataset(train_dir_path, test_dir_path):\n",
    "    '''\n",
    "    load dataset as train and test\n",
    "    '''\n",
    "    files_prefix = ['total_acc_x_', 'total_acc_y_', 'total_acc_z_', 'body_acc_x_',\n",
    "                    'body_acc_y_', 'body_acc_z_', 'body_gyro_x_', 'body_gyro_y_', 'body_gyro_z_']\n",
    "\n",
    "    train_files = [train_dir_path + 'Inertial Signals/' +\n",
    "                   pre + 'train.txt' for pre in files_prefix]\n",
    "    test_files = [test_dir_path + 'Inertial Signals/' +\n",
    "                  pre + 'test.txt' for pre in files_prefix]\n",
    "\n",
    "    train_X = load_group(train_files)\n",
    "    train_y = load_file(train_dir_path + 'y_train.txt')\n",
    "\n",
    "    test_X = load_group(test_files)\n",
    "    test_y = load_file(test_dir_path + 'y_test.txt')\n",
    "\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def scale_data(X):\n",
    "    '''\n",
    "    scale data to [-1, 1]\n",
    "    '''\n",
    "    scaled = X / abs(X).max()\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def scale_dataset(dataset):\n",
    "    scaled = []\n",
    "    for i in range(dataset.shape[-1]):\n",
    "        scaled.append(scale_data(dataset[..., i]))\n",
    "    return np.dstack(scaled)\n",
    "\n",
    "\n",
    "def data_for_subject(X, y, sub_map, sub_id):\n",
    "    '''\n",
    "    get data for one subject\n",
    "    '''\n",
    "    xi = [i for i in range(len(sub_map)) if sub_map[i] == sub_id]\n",
    "    return X[xi], y[xi]\n",
    "\n",
    "\n",
    "def to_series(windows):\n",
    "    '''\n",
    "    remove overlap and convert a series of continuous windows to a 1D list\n",
    "    '''\n",
    "    series = []\n",
    "    n, win_size = windows.shape\n",
    "    series += list(windows[0][:win_size // 2])\n",
    "    for i in range(n):\n",
    "        series += list(windows[i][win_size // 2:])\n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQYHTPvN4Ct_"
   },
   "source": [
    "Load train data and test test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JkRuTW2B3rFj",
    "outputId": "6604c9af-ce01-4be8-962f-bb7f236c9db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10299, 128, 9) (10299,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = load_dataset(\n",
    "    PATH + 'train/', PATH + 'test/')\n",
    "\n",
    "# zero-offset class values\n",
    "train_y -= 1\n",
    "test_y -= 1\n",
    "\n",
    "total_X = np.vstack((train_X, test_X))\n",
    "total_y = np.vstack((train_y, test_y))\n",
    "total_y = total_y.reshape(total_y.shape[0])\n",
    "\n",
    "print(total_X.shape, total_y.shape)\n",
    "\n",
    "train_sub_map = load_file(PATH + 'train/subject_train.txt')\n",
    "test_sub_map = load_file(PATH + 'test/subject_test.txt')\n",
    "sub_map = np.vstack((train_sub_map, test_sub_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7A6FGiyMyUdl"
   },
   "outputs": [],
   "source": [
    "har_uda_root = '/content/gdrive/My Drive/har-uda/'\n",
    "data_path = har_uda_root+'data/'\n",
    "ckp_path = har_uda_root+'checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0EwwCiN6y6o5"
   },
   "outputs": [],
   "source": [
    "sub_num = 30\n",
    "sub_data = []\n",
    "\n",
    "for i in range(sub_num):\n",
    "    data_x, data_y = data_for_subject(total_X, total_y, sub_map, i+1)\n",
    "    data_x= scale_dataset(data_x)\n",
    "\n",
    "    data_x_train, data_x_test, data_y_train, data_y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=1, stratify=data_y)\n",
    "    data_x_train, data_x_val, data_y_train, data_y_val = train_test_split(data_x_train, data_y_train, test_size=0.3, random_state=1, stratify=data_y_train)\n",
    "    \n",
    "    data_list = [data_x_train, data_x_val, data_x_test, data_y_train, data_y_val, data_y_test]\n",
    "    name_list = ['data_x_train', 'data_x_val', 'data_x_test', 'data_y_train', 'data_y_val', 'data_y_test']\n",
    "    data_i = {}\n",
    "    for data_ele, name in zip(data_list, name_list):\n",
    "        data_i[name] = data_ele\n",
    "        save_path = data_path + name + '_{}.npy'.format(i+1)\n",
    "        np.save(save_path, data_ele)\n",
    "    sub_data.append(data_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIo-Ocrs5iL-"
   },
   "source": [
    "### Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJ_IxeKi5kag"
   },
   "outputs": [],
   "source": [
    "def plot_window(window, fig_title='window'):\n",
    "    '''\n",
    "    plot the data in a window\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    n = window.shape[-1]\n",
    "\n",
    "    axis = ['x', 'y', 'z']\n",
    "    title = ['total acc ' + i for i in axis] + ['body acc ' +\n",
    "                                                i for i in axis] + ['body gyro ' + i for i in axis]\n",
    "    for i in range(n):\n",
    "        ax = fig.add_subplot(n, 1, i+1)\n",
    "        ax.plot(window[:,i], 'r')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.set_ylim([-1.0, 1.0])\n",
    "        # ax.set_title(title[i])\n",
    "    \n",
    "    fig.suptitle(fig_title)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def class_breakdown(data):\n",
    "    '''\n",
    "    summarize the balance of classes\n",
    "    '''\n",
    "    # activities = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
    "    df = pd.DataFrame(data)\n",
    "    df[0].value_counts().plot(kind='bar', title='Acticity')\n",
    "    plt.show()\n",
    "\n",
    "def plot_subject(X, y):\n",
    "    '''\n",
    "    plot the data for a single subject\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(10, 20))\n",
    "    n = X.shape[2] + 1\n",
    "    axis = ['x', 'y', 'z']\n",
    "    title = ['total acc ' + i for i in axis] + ['body acc ' +\n",
    "                                                i for i in axis] + ['body gyro ' + i for i in axis]\n",
    "    for i in range(n-1):\n",
    "        ax = fig.add_subplot(n, 1, i + 1)\n",
    "        series = to_series(X[..., i])\n",
    "        ax.plot(series, 'r')\n",
    "        ax.set_title(title[i])\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.set_ylim([min(series) - np.std(series), max(series) + np.std(series)])\n",
    "        ax.grid(True)\n",
    "\n",
    "    ax = fig.add_subplot(n, 1, n)\n",
    "    ax.plot(y, 'g')\n",
    "    ax.set_title('activity')\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHzyV_Jf9opy"
   },
   "source": [
    "## Classifier model\n",
    "\n",
    "Use a multi-layers CNN as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPWwUgx0IXCV"
   },
   "outputs": [],
   "source": [
    "# dataset parameters\n",
    "TIMESTEP = 128\n",
    "CHANNELS = 9\n",
    "WIN_SHAPE = (TIMESTEP, CHANNELS)\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "# model parameters\n",
    "CLASSIFIER_FILTERS = 64\n",
    "\n",
    "# train parameters\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMqUafVD96Na"
   },
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    input = tf.keras.layers.Input(shape=WIN_SHAPE)\n",
    "\n",
    "    c = tf.keras.layers.Conv1D(CLASSIFIER_FILTERS, 5, activation='relu')(input)\n",
    "    c = tf.keras.layers.Conv1D(CLASSIFIER_FILTERS, 5, activation='relu')(c)\n",
    "    c = tf.keras.layers.Conv1D(CLASSIFIER_FILTERS, 5, activation='relu')(c)\n",
    "    c = tf.keras.layers.Conv1D(CLASSIFIER_FILTERS, 5, activation='relu')(c)\n",
    "\n",
    "    c = tf.keras.layers.Dropout(0.5)(c)\n",
    "    c = tf.keras.layers.LSTM(TIMESTEP, return_sequences=True)(c)\n",
    "    c = tf.keras.layers.Dropout(0.5)(c)\n",
    "    c = tf.keras.layers.LSTM(TIMESTEP, return_sequences=True)(c)\n",
    "\n",
    "    c = tf.keras.layers.Flatten()(c)\n",
    "    c = tf.keras.layers.Dropout(0.5)(c)\n",
    "    output = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(c)\n",
    "\n",
    "    return tf.keras.Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SU8ai3FZ-OHN"
   },
   "source": [
    "train classifier using target subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2V_hJ3_1IqU"
   },
   "outputs": [],
   "source": [
    "sub_num = 30\n",
    "classifiers = []\n",
    "for i in range(sub_num):\n",
    "    model_path = ckp_path + 'classifier_{}.hdf5'.format(i+1)\n",
    "\n",
    "    x_train = sub_data[i]['data_x_train']\n",
    "    y_train = tf.one_hot(sub_data[i]['data_y_train'], NUM_CLASSES)\n",
    "    x_val = sub_data[i]['data_x_val']\n",
    "    y_val = tf.one_hot(sub_data[i]['data_y_val'], NUM_CLASSES)\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5)\n",
    "    mc = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
    "    \n",
    "    model = build_classifier()\n",
    "    model.compile(optimizer='rmsprop', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    classifiers.append(model)\n",
    "\n",
    "    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=4, verbose=0, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WPhwJlSDWDw2",
    "outputId": "92a461c0-e303-4247-9734-7020a02fa130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 6.6106e-06 - accuracy: 1.0000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2117 - accuracy: 0.7213\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.2687 - accuracy: 0.8406\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5711 - accuracy: 0.5781\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.9558 - accuracy: 0.7213\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.1566 - accuracy: 0.8154\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7790 - accuracy: 0.8387\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9111 - accuracy: 0.8772\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.7941 - accuracy: 0.6034\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.4968 - accuracy: 0.5593\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3649 - accuracy: 0.8594\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0153 - accuracy: 0.8125\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.0422 - accuracy: 0.7879\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.4805 - accuracy: 0.7538\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.9848 - accuracy: 0.7727\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.4125 - accuracy: 0.5946\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.5494 - accuracy: 0.6351\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6807 - accuracy: 0.9452\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7622 - accuracy: 0.8611\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1141 - accuracy: 0.8028\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.7664 - accuracy: 0.6585\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.2646 - accuracy: 0.7846\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4938 - accuracy: 0.8267\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1220 - accuracy: 0.8571\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2898 - accuracy: 0.7683\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.9718 - accuracy: 0.8481\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.4048 - accuracy: 0.8816\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.4413 - accuracy: 0.7013\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7229 - accuracy: 0.8696\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.7792 - accuracy: 0.8312\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.3721 - accuracy: 0.9143\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4831e-05 - accuracy: 1.0000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0493 - accuracy: 0.7971\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.5890 - accuracy: 0.4531\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.5399 - accuracy: 0.5410\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.0855 - accuracy: 0.8000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.7590 - accuracy: 0.6774\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.0197 - accuracy: 0.7719\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.6242 - accuracy: 0.6034\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12.2754 - accuracy: 0.4237\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.5602 - accuracy: 0.5625\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.1384 - accuracy: 0.7812\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.6713 - accuracy: 0.6970\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.1405 - accuracy: 0.5846\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.0781 - accuracy: 0.6970\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5.2166 - accuracy: 0.5811\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.7794 - accuracy: 0.6757\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3946 - accuracy: 0.7945\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.3080 - accuracy: 0.7500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.2936 - accuracy: 0.7606\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.8225 - accuracy: 0.6341\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9698 - accuracy: 0.8154\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.4977 - accuracy: 0.7333\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.0240 - accuracy: 0.7403\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 10.6101 - accuracy: 0.4268\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 5.9807 - accuracy: 0.7342\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7484 - accuracy: 0.8816\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.8417 - accuracy: 0.7273\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0033 - accuracy: 0.5072\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 6.0813 - accuracy: 0.6753\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8857\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3690 - accuracy: 0.6393\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0102e-04 - accuracy: 1.0000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.6843 - accuracy: 0.3906\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2555 - accuracy: 0.5410\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.8615\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2742 - accuracy: 0.9194\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0069 - accuracy: 0.6842\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.5868 - accuracy: 0.3793\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.0953 - accuracy: 0.4576\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2519 - accuracy: 0.7031\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7178 - accuracy: 0.7812\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2275 - accuracy: 0.9697\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.8154\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5556 - accuracy: 0.8788\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.5986 - accuracy: 0.6486\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7367 - accuracy: 0.8243\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8493\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1670 - accuracy: 0.9306\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9718\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.5858 - accuracy: 0.7561\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8769\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.8933\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9740\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.1747 - accuracy: 0.5854\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5647 - accuracy: 0.8101\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.9737\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.4116 - accuracy: 0.7532\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6175 - accuracy: 0.6232\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.3779 - accuracy: 0.7532\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 12.8430 - accuracy: 0.3429\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14.3013 - accuracy: 0.3279\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.2819 - accuracy: 0.4928\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2379 - accuracy: 0.9688\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3527 - accuracy: 0.9016\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.5485 - accuracy: 0.5077\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.9228 - accuracy: 0.4516\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 6.7326 - accuracy: 0.4912\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.2362 - accuracy: 0.4310\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18.0028 - accuracy: 0.2542\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9688 - accuracy: 0.5781\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.5928 - accuracy: 0.4062\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.7329 - accuracy: 0.4545\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5117 - accuracy: 0.4462\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.8720 - accuracy: 0.5455\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.3262 - accuracy: 0.2297\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 16.4525 - accuracy: 0.4459\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 11.0455 - accuracy: 0.4658\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4316 - accuracy: 0.5139\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2379 - accuracy: 0.5493\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.1553 - accuracy: 0.4390\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0916 - accuracy: 0.5538\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.8962 - accuracy: 0.5067\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.6236 - accuracy: 0.5195\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.9395 - accuracy: 0.7805\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.1849 - accuracy: 0.6709\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.4145 - accuracy: 0.5132\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 20.5921 - accuracy: 0.2727\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.1193 - accuracy: 0.5797\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.3924 - accuracy: 0.4156\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.7400 - accuracy: 0.6000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.8239 - accuracy: 0.5574\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4.4707 - accuracy: 0.6522\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.7792 - accuracy: 0.6250\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.9016\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.9586 - accuracy: 0.7231\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.5409 - accuracy: 0.5968\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.5610 - accuracy: 0.5439\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5.3994 - accuracy: 0.6207\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.5052 - accuracy: 0.3559\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.9949 - accuracy: 0.7188\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5703 - accuracy: 0.7500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.4581 - accuracy: 0.5758\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.3733 - accuracy: 0.2923\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7328 - accuracy: 0.7727\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.2583 - accuracy: 0.2297\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 12.3510 - accuracy: 0.5000\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.9855 - accuracy: 0.6027\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7701 - accuracy: 0.8750\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8732 - accuracy: 0.7465\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 19.0580 - accuracy: 0.2317\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.3359 - accuracy: 0.8000\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 7.7901 - accuracy: 0.3733\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.0764 - accuracy: 0.6234\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.8344 - accuracy: 0.6951\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.4084 - accuracy: 0.8228\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.1712 - accuracy: 0.9079\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 7.4673 - accuracy: 0.3377\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8781 - accuracy: 0.7536\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 5.3800 - accuracy: 0.5065\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1501 - accuracy: 0.7286\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.4600 - accuracy: 0.6066\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0861 - accuracy: 0.8116\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.4947 - accuracy: 0.6562\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.5538 - accuracy: 0.6885\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.8474e-04 - accuracy: 1.0000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1684 - accuracy: 0.6129\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.3038 - accuracy: 0.7018\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 8.1340 - accuracy: 0.5172\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 14.9997 - accuracy: 0.4915\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0785 - accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3377 - accuracy: 0.7656\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.6218 - accuracy: 0.7424\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.3153 - accuracy: 0.6615\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.5896 - accuracy: 0.8636\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.6306 - accuracy: 0.4324\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 7.0990 - accuracy: 0.5405\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.7734 - accuracy: 0.7671\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6264 - accuracy: 0.8472\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3161 - accuracy: 0.6901\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.0432 - accuracy: 0.5854\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.2062 - accuracy: 0.8000\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.7018 - accuracy: 0.6667\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.7092 - accuracy: 0.8571\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.6849 - accuracy: 0.7805\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.8638 - accuracy: 0.8734\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.0089 - accuracy: 0.7763\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.1193 - accuracy: 0.5714\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.4971 - accuracy: 0.8406\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.3656 - accuracy: 0.7273\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10.7348 - accuracy: 0.4429\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.3256 - accuracy: 0.4754\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.1540 - accuracy: 0.6087\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11.7891 - accuracy: 0.3594\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10.9876 - accuracy: 0.3934\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.7234 - accuracy: 0.5385\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2024 - accuracy: 0.8065\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.7075 - accuracy: 0.4912\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.8914 - accuracy: 0.3448\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 15.4523 - accuracy: 0.2203\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 13.3848 - accuracy: 0.4062\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.9936 - accuracy: 0.5938\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.3224 - accuracy: 0.5909\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.5071 - accuracy: 0.5077\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.8155 - accuracy: 0.5455\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 7.0736 - accuracy: 0.3784\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5.2789 - accuracy: 0.5000\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 8.4867 - accuracy: 0.5616\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 13.1231 - accuracy: 0.5417\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.0376 - accuracy: 0.5915\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0364 - accuracy: 0.4390\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.9966 - accuracy: 0.5385\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5.2399 - accuracy: 0.5867\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.3541 - accuracy: 0.7013\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 11.0808 - accuracy: 0.4268\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 13.7884 - accuracy: 0.5063\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.7698 - accuracy: 0.6184\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.4111 - accuracy: 0.5325\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 14.8930 - accuracy: 0.4348\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 12.1874 - accuracy: 0.4156\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4.7155 - accuracy: 0.7000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.0688 - accuracy: 0.6885\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2254 - accuracy: 0.8841\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11.5601 - accuracy: 0.5156\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.6261 - accuracy: 0.6393\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.7735 - accuracy: 0.8769\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.1256 - accuracy: 0.6935\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.6036e-04 - accuracy: 1.0000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.8094 - accuracy: 0.6552\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.9622 - accuracy: 0.4746\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10.7988 - accuracy: 0.5938\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.5780 - accuracy: 0.6406\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.6185 - accuracy: 0.8636\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.6184 - accuracy: 0.8769\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.3810 - accuracy: 0.6364\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 7.1060 - accuracy: 0.6622\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.9405 - accuracy: 0.7432\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7975 - accuracy: 0.8219\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.0795 - accuracy: 0.8611\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.9522 - accuracy: 0.8592\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.9550 - accuracy: 0.7561\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.7586 - accuracy: 0.7846\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.3485 - accuracy: 0.8933\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9870\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.1996 - accuracy: 0.6098\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 5.3783 - accuracy: 0.6962\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.9474\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.2084 - accuracy: 0.7143\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.5402 - accuracy: 0.6812\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 5.8642 - accuracy: 0.6494\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.1501 - accuracy: 0.7000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8884 - accuracy: 0.5574\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9403 - accuracy: 0.6232\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6666 - accuracy: 0.4844\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9110 - accuracy: 0.6230\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.7267 - accuracy: 0.4000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6456 - accuracy: 0.7258\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7258 - accuracy: 0.6667\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2960 - accuracy: 0.8103\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.0889 - accuracy: 0.5085\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3479 - accuracy: 0.3281\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6241 - accuracy: 0.6094\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1577 - accuracy: 0.5909\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.6615\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.8183 - accuracy: 0.6061\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0977 - accuracy: 0.6216\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6110 - accuracy: 0.6486\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9711 - accuracy: 0.6712\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2371 - accuracy: 0.7222\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8224 - accuracy: 0.6901\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.6207 - accuracy: 0.6220\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9325 - accuracy: 0.7231\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.6800\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.8052\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5421 - accuracy: 0.5366\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.2128 - accuracy: 0.6962\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8158\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.7819 - accuracy: 0.6364\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9460 - accuracy: 0.7101\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1541 - accuracy: 0.6494\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7560 - accuracy: 0.7571\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.8361\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8190 - accuracy: 0.3333\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5500 - accuracy: 0.6875\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5931 - accuracy: 0.7705\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9331 - accuracy: 0.7231\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.9159 - accuracy: 0.5000\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3573 - accuracy: 0.9298\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.7942 - accuracy: 0.7069\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7601 - accuracy: 0.7656\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5607 - accuracy: 0.7344\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.4789 - accuracy: 0.4848\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.6789 - accuracy: 0.2154\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.1518 - accuracy: 0.7879\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.0733 - accuracy: 0.5000\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.0178 - accuracy: 0.3243\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.8951 - accuracy: 0.5890\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.7778\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.5492 - accuracy: 0.6056\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 12.4500 - accuracy: 0.2073\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7390 - accuracy: 0.7077\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.9017 - accuracy: 0.5200\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.5955 - accuracy: 0.5584\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4982 - accuracy: 0.7439\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7848\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.2755 - accuracy: 0.7632\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.0998 - accuracy: 0.6364\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8406\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.2908 - accuracy: 0.5325\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6855 - accuracy: 0.8714\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.2761 - accuracy: 0.7541\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1040 - accuracy: 0.8406\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7120 - accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4864 - accuracy: 0.8525\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7188 - accuracy: 0.9077\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4869 - accuracy: 0.7097\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1776 - accuracy: 0.9649\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.9080 - accuracy: 0.6552\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 7.1765 - accuracy: 0.5254\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9259e-06 - accuracy: 1.0000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8642 - accuracy: 0.7812\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.4140 - accuracy: 0.7121\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.5279 - accuracy: 0.5077\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.1776 - accuracy: 0.3649\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.2104 - accuracy: 0.5946\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8888 - accuracy: 0.8082\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3.1674e-04 - accuracy: 1.0000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0312 - accuracy: 0.9155\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.0591 - accuracy: 0.3780\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.6732 - accuracy: 0.8769\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6417 - accuracy: 0.7733\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1716 - accuracy: 0.9221\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6183 - accuracy: 0.8902\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9873\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9737\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 6.8653 - accuracy: 0.6364\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2113 - accuracy: 0.9565\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.1503 - accuracy: 0.7403\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.4399 - accuracy: 0.6571\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11.3279 - accuracy: 0.4918\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.7371 - accuracy: 0.8116\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.3528 - accuracy: 0.5625\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.2867 - accuracy: 0.7213\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.0315 - accuracy: 0.8769\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.9206 - accuracy: 0.7742\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.6472 - accuracy: 0.8246\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18.1376 - accuracy: 0.3966\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21.6166 - accuracy: 0.4407\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.8064 - accuracy: 0.6719\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1914 - accuracy: 0.9844\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.3820 - accuracy: 0.7121\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.4053 - accuracy: 0.7077\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.1907 - accuracy: 0.6515\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.3429 - accuracy: 0.5405\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.1688 - accuracy: 0.7973\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.1863 - accuracy: 0.7945\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0485 - accuracy: 0.8611\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.3315 - accuracy: 0.8451\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.0514 - accuracy: 0.8049\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.3028 - accuracy: 0.9077\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.4679 - accuracy: 0.7733\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.9235 - accuracy: 0.8831\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.3062 - accuracy: 0.6341\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.0146 - accuracy: 0.8228\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.7727 - accuracy: 0.9211\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 11.9564 - accuracy: 0.6364\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.4769 - accuracy: 0.7971\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.1731 - accuracy: 0.6364\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7520 - accuracy: 0.8000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1303 - accuracy: 0.8361\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.9420\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0787 - accuracy: 0.7188\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6278 - accuracy: 0.7213\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9932 - accuracy: 0.6923\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0525 - accuracy: 0.7742\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.4461 - accuracy: 0.7193\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5.1129 - accuracy: 0.4310\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.2087 - accuracy: 0.4237\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8195 - accuracy: 0.6406\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0107 - accuracy: 0.6462\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2995 - accuracy: 0.9242\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.9806 - accuracy: 0.6351\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8514\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.1507 - accuracy: 0.9452\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.2367 - accuracy: 0.7639\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9718\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.9246e-04 - accuracy: 1.0000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8742 - accuracy: 0.8615\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0354 - accuracy: 0.7600\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1409 - accuracy: 0.9481\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.7678 - accuracy: 0.7195\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.5172 - accuracy: 0.7215\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.7561 - accuracy: 0.8026\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.6206 - accuracy: 0.6883\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.5981 - accuracy: 0.7246\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.9631 - accuracy: 0.5714\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.5308 - accuracy: 0.5429\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7414 - accuracy: 0.8525\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4.8323 - accuracy: 0.7246\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 14.7011 - accuracy: 0.2812\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 14.0754 - accuracy: 0.3443\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.1365 - accuracy: 0.5538\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.6671 - accuracy: 0.6613\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.3703 - accuracy: 0.5439\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4933 - accuracy: 0.5172\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.5234 - accuracy: 0.2034\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.7703 - accuracy: 0.4219\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6733 - accuracy: 0.6094\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.2676 - accuracy: 0.6364\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9846\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.9006 - accuracy: 0.5455\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.2068 - accuracy: 0.7432\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.3216 - accuracy: 0.7973\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.0703 - accuracy: 0.6027\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.5958 - accuracy: 0.5833\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.4255 - accuracy: 0.6620\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.9390\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.2637 - accuracy: 0.6462\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6369 - accuracy: 0.8533\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6623 - accuracy: 0.7662\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 10.4435 - accuracy: 0.3780\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6910 - accuracy: 0.4051\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7368 - accuracy: 0.7368\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4.6091 - accuracy: 0.6494\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10.6077 - accuracy: 0.4493\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 5.9416 - accuracy: 0.5974\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8857\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3397 - accuracy: 0.6066\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8986\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.8281\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5318 - accuracy: 0.6885\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2726 - accuracy: 0.9538\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0226 - accuracy: 0.7742\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6417 - accuracy: 0.9298\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 6.0086 - accuracy: 0.6034\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.8209 - accuracy: 0.5254\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7292e-04 - accuracy: 1.0000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7063 - accuracy: 0.7500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.2911 - accuracy: 0.7121\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.3886 - accuracy: 0.6615\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.7141e-05 - accuracy: 1.0000\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 6.7721 - accuracy: 0.4595\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.1640 - accuracy: 0.5946\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.1789 - accuracy: 0.8219\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1549 - accuracy: 0.9722\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.8732\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.8934 - accuracy: 0.5610\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9820 - accuracy: 0.8615\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5918 - accuracy: 0.8267\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9610\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1989 - accuracy: 0.8171\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5645 - accuracy: 0.9367\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9737\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.4309 - accuracy: 0.6753\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8688 - accuracy: 0.7971\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1316 - accuracy: 0.8052\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 11.4624 - accuracy: 0.4000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.4790 - accuracy: 0.6393\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.2264 - accuracy: 0.7246\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 21.6906 - accuracy: 0.2969\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 19.1694 - accuracy: 0.3934\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.4216 - accuracy: 0.3846\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.3804 - accuracy: 0.6452\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12.4626 - accuracy: 0.4035\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.3127 - accuracy: 0.5862\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.0881 - accuracy: 0.2034\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 26.4008 - accuracy: 0.1875\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 17.5586 - accuracy: 0.3594\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.5166 - accuracy: 0.6212\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.4168 - accuracy: 0.7846\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 27.7493 - accuracy: 0.2273\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.7153 - accuracy: 0.7027\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 11.8915 - accuracy: 0.4932\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 19.8280 - accuracy: 0.4444\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 12.9277 - accuracy: 0.4648\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8780\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.3582 - accuracy: 0.3692\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.1509 - accuracy: 0.6667\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 5.9051 - accuracy: 0.6883\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 19.7747 - accuracy: 0.3780\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 24.3462 - accuracy: 0.3671\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 12.4772 - accuracy: 0.5658\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 14.3323 - accuracy: 0.4675\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.4672 - accuracy: 0.3333\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.3994 - accuracy: 0.3636\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9104 - accuracy: 0.4000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2547 - accuracy: 0.7377\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.8974 - accuracy: 0.8261\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 17.3765 - accuracy: 0.3906\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.0963 - accuracy: 0.4262\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.2123 - accuracy: 0.4769\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1827 - accuracy: 0.6613\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.1054 - accuracy: 0.4561\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.8670 - accuracy: 0.4483\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 17.4109 - accuracy: 0.2034\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 16.8487 - accuracy: 0.3281\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1117 - accuracy: 0.4375\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.2426 - accuracy: 0.7879\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.8769\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9023 - accuracy: 0.3485\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.3933 - accuracy: 0.7838\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.4780e-05 - accuracy: 1.0000\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.5931 - accuracy: 0.5205\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.5733 - accuracy: 0.4306\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3522 - accuracy: 0.5352\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.8115 - accuracy: 0.9146\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.6677 - accuracy: 0.4154\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7157 - accuracy: 0.8000\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.5922 - accuracy: 0.7792\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 15.9364 - accuracy: 0.3537\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.2020 - accuracy: 0.3671\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.0421 - accuracy: 0.6053\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.3368 - accuracy: 0.5714\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 16.0046 - accuracy: 0.3333\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 11.7250 - accuracy: 0.3766\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2692 - accuracy: 0.8857\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.0523 - accuracy: 0.7377\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.9706 - accuracy: 0.6812\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.9583 - accuracy: 0.5938\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.2812 - accuracy: 0.6721\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0905 - accuracy: 0.8769\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.5563 - accuracy: 0.6452\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.2955 - accuracy: 0.7018\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 8.8066 - accuracy: 0.5000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 17.6252 - accuracy: 0.4237\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1320 - accuracy: 0.7188\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.9867 - accuracy: 0.6875\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.7998 - accuracy: 0.8636\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.8844 - accuracy: 0.6615\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.3500 - accuracy: 0.6212\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.6362 - accuracy: 0.5270\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5493 - accuracy: 0.7027\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.1898 - accuracy: 0.9726\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3266 - accuracy: 0.7222\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8520 - accuracy: 0.8028\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.8780\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2467 - accuracy: 0.9231\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7878 - accuracy: 0.7333\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.1433 - accuracy: 0.8052\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.0844 - accuracy: 0.7073\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.6551 - accuracy: 0.6962\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3314 - accuracy: 0.8158\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 7.5998 - accuracy: 0.6234\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2667 - accuracy: 0.7826\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.3295 - accuracy: 0.7662\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8743 - accuracy: 0.9000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8762 - accuracy: 0.7377\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1424 - accuracy: 0.7681\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7902 - accuracy: 0.5625\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8457 - accuracy: 0.7377\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.7075 - accuracy: 0.7538\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7455 - accuracy: 0.7258\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4255 - accuracy: 0.8947\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.4970 - accuracy: 0.6379\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.4328 - accuracy: 0.3559\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.3048 - accuracy: 0.7344\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4029 - accuracy: 0.7344\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.3471 - accuracy: 0.6061\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.3913 - accuracy: 0.2923\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9082 - accuracy: 0.7727\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.6178 - accuracy: 0.2297\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0123 - accuracy: 0.6892\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.9680 - accuracy: 0.7671\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7022e-07 - accuracy: 1.0000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.3341 - accuracy: 0.8169\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 12.3824 - accuracy: 0.4390\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8923\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5.0024 - accuracy: 0.7600\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.6131 - accuracy: 0.8182\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.5222 - accuracy: 0.7317\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.8070 - accuracy: 0.7848\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2013 - accuracy: 0.9474\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.7226 - accuracy: 0.5584\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0590 - accuracy: 0.8406\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.9975 - accuracy: 0.8571\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.5901 - accuracy: 0.6885\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.9275\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.3403 - accuracy: 0.6719\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.5432 - accuracy: 0.6230\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.9538\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.3638 - accuracy: 0.7419\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.4323 - accuracy: 0.7368\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 15.4899 - accuracy: 0.4138\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.2926 - accuracy: 0.4746\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.0657 - accuracy: 0.7969\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7352 - accuracy: 0.9242\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.8872 - accuracy: 0.4923\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4058 - accuracy: 0.7879\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.5995 - accuracy: 0.5135\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.1853 - accuracy: 0.7162\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.2766 - accuracy: 0.8904\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.8624 - accuracy: 0.8750\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.3374e-05 - accuracy: 1.0000\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9878\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1015 - accuracy: 0.9846\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.3650 - accuracy: 0.7467\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.9221\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.6959 - accuracy: 0.8171\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.7180 - accuracy: 0.8861\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2884 - accuracy: 0.9211\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.4875 - accuracy: 0.7792\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.9672 - accuracy: 0.7246\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.7306 - accuracy: 0.7792\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.0191 - accuracy: 0.7286\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9234 - accuracy: 0.7705\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.1906 - accuracy: 0.7681\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.6272 - accuracy: 0.4531\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.0878 - accuracy: 0.4262\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.8295 - accuracy: 0.4615\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.3465 - accuracy: 0.8226\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.4016 - accuracy: 0.7193\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.8498 - accuracy: 0.6379\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 6.7407 - accuracy: 0.2542\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.4315 - accuracy: 0.4062\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.1658 - accuracy: 0.5156\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0198 - accuracy: 0.8939\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.9077\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4.3485 - accuracy: 0.5000\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2.3920 - accuracy: 0.7838\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7951 - accuracy: 0.6986\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3.8145 - accuracy: 0.6111\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.0533 - accuracy: 0.7746\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.7870e-06 - accuracy: 1.0000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.9246 - accuracy: 0.6923\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.3556 - accuracy: 0.9067\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.1706 - accuracy: 0.8312\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.3126 - accuracy: 0.4390\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.9895 - accuracy: 0.4937\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.7174 - accuracy: 0.6974\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 4.1943 - accuracy: 0.6883\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.5765 - accuracy: 0.6377\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 3.2970 - accuracy: 0.6883\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.1667 - accuracy: 0.6714\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11.4406 - accuracy: 0.5738\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.6610 - accuracy: 0.7101\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.5437 - accuracy: 0.5781\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.7796 - accuracy: 0.6557\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4.3215 - accuracy: 0.7077\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3328 - accuracy: 0.8387\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7250 - accuracy: 0.8772\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 6.7678 - accuracy: 0.6034\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 15.6152 - accuracy: 0.2881\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5662 - accuracy: 0.7812\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9025 - accuracy: 0.7500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4.3339 - accuracy: 0.6818\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.4502 - accuracy: 0.5846\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8427 - accuracy: 0.9091\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 12.6131 - accuracy: 0.3919\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0706 - accuracy: 0.8784\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.7146 - accuracy: 0.7397\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6049 - accuracy: 0.7917\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.6191 - accuracy: 0.8169\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.8774 - accuracy: 0.6951\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 5.6854e-08 - accuracy: 1.0000\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.8540 - accuracy: 0.8533\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.8014 - accuracy: 0.8701\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.0167 - accuracy: 0.7683\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.8501 - accuracy: 0.9367\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5667 - accuracy: 0.9342\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 7.6968 - accuracy: 0.6623\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1571 - accuracy: 0.8841\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.3295 - accuracy: 0.7792\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3388 - accuracy: 0.8286\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.8577 - accuracy: 0.7213\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2768 - accuracy: 0.7536\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.4983 - accuracy: 0.6250\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8045 - accuracy: 0.6066\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.8809 - accuracy: 0.6462\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8592 - accuracy: 0.7097\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.7305 - accuracy: 0.9123\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 6.3242 - accuracy: 0.4828\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.6430 - accuracy: 0.4407\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.5073 - accuracy: 0.5156\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.3259 - accuracy: 0.6250\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.2019 - accuracy: 0.7727\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.8573 - accuracy: 0.7077\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.1389 - accuracy: 0.7273\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 8.7532 - accuracy: 0.4595\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.8936 - accuracy: 0.7297\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.2785 - accuracy: 0.7534\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9590 - accuracy: 0.8333\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3600 - accuracy: 0.8028\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.8423 - accuracy: 0.8293\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1246 - accuracy: 0.9846\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9867\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8831\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.9774 - accuracy: 0.6829\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.1440 - accuracy: 0.7468\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.9342\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.7092 - accuracy: 0.7013\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1781 - accuracy: 0.9275\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.6078 - accuracy: 0.7403\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.3287 - accuracy: 0.8286\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.4294 - accuracy: 0.7213\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1702 - accuracy: 0.7681\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2558 - accuracy: 0.6875\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6802 - accuracy: 0.8361\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.8050 - accuracy: 0.8000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6713 - accuracy: 0.8710\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5949 - accuracy: 0.8772\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5.6622 - accuracy: 0.6034\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.5948 - accuracy: 0.4407\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.9126 - accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.2483 - accuracy: 0.6406\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.0685 - accuracy: 0.6061\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.6212 - accuracy: 0.4615\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.8040 - accuracy: 0.7727\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.5471 - accuracy: 0.2568\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 8.4532 - accuracy: 0.6486\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.1764 - accuracy: 0.6986\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.9101 - accuracy: 0.8732\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 13.2258 - accuracy: 0.3780\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1089 - accuracy: 0.9846\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.8337 - accuracy: 0.7867\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1625 - accuracy: 0.9610\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.3161 - accuracy: 0.6829\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3102 - accuracy: 0.9241\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.9342\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 10.2817 - accuracy: 0.6753\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2607 - accuracy: 0.8116\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3.0291 - accuracy: 0.7662\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1425 - accuracy: 0.9571\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.2280 - accuracy: 0.7377\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.9130\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4110 - accuracy: 0.9219\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.0989 - accuracy: 0.8689\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.9385\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8085 - accuracy: 0.7903\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 7.2137 - accuracy: 0.7368\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 7.7536 - accuracy: 0.6552\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 11.8369 - accuracy: 0.6610\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8906\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6416 - accuracy: 0.7812\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.8620 - accuracy: 0.7879\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.6944 - accuracy: 0.5692\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.7221 - accuracy: 0.8333\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 10.6382 - accuracy: 0.7027\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.0509 - accuracy: 0.8243\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.7214 - accuracy: 0.8219\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9194 - accuracy: 0.8472\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7657 - accuracy: 0.9014\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.2928 - accuracy: 0.7683\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7049 - accuracy: 0.8923\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.6398 - accuracy: 0.7333\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.8489 - accuracy: 0.8961\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.2972e-05 - accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.6020 - accuracy: 0.8987\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.9342\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.2889 - accuracy: 0.7662\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.5662 - accuracy: 0.7391\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.7623 - accuracy: 0.8701\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 15.0432 - accuracy: 0.4714\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 19.9012 - accuracy: 0.5082\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 16.0467 - accuracy: 0.5507\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.9753 - accuracy: 0.7969\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.2192 - accuracy: 0.5574\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.4164 - accuracy: 0.6154\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 15.2312 - accuracy: 0.5323\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12.4128 - accuracy: 0.6140\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12.3303 - accuracy: 0.4655\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 15.7828 - accuracy: 0.3051\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4093 - accuracy: 0.8125\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 13.0377 - accuracy: 0.5469\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.5352 - accuracy: 0.5606\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 24.3750 - accuracy: 0.2615\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.3394 - accuracy: 0.5909\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.6013 - accuracy: 0.2838\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.3647 - accuracy: 0.3784\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 11.4355 - accuracy: 0.5753\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4033 - accuracy: 0.7500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 11.6353 - accuracy: 0.6761\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 24.0535 - accuracy: 0.3659\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.8395 - accuracy: 0.8000\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.6647 - accuracy: 0.4267\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 13.0078 - accuracy: 0.5974\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.5622 - accuracy: 0.7805\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 0.9873\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.8141 - accuracy: 0.7237\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.2735 - accuracy: 0.4026\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.8841\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.0482 - accuracy: 0.6104\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6297 - accuracy: 0.9143\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9436 - accuracy: 0.9016\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7699 - accuracy: 0.8986\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.1825 - accuracy: 0.5000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.3716 - accuracy: 0.5738\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.2092 - accuracy: 0.7077\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.9355\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6397 - accuracy: 0.8947\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.8547 - accuracy: 0.5000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 7.1191 - accuracy: 0.3559\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.4765 - accuracy: 0.6094\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4155 - accuracy: 0.7031\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.5999 - accuracy: 0.8182\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.0572 - accuracy: 0.6000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.7701 - accuracy: 0.6667\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.9749 - accuracy: 0.6757\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.3190 - accuracy: 0.7432\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.9859 - accuracy: 0.8356\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.8926 - accuracy: 0.9028\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2037 - accuracy: 0.7887\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.9035 - accuracy: 0.6463\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9287 - accuracy: 0.8154\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8773 - accuracy: 0.8667\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.9221\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.1084 - accuracy: 0.5976\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.6121 - accuracy: 0.7342\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9868\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.7916 - accuracy: 0.7143\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.9761 - accuracy: 0.8551\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.7940 - accuracy: 0.8182\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.7647 - accuracy: 0.6429\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5682 - accuracy: 0.8852\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8954 - accuracy: 0.7391\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.6326 - accuracy: 0.4844\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.5660 - accuracy: 0.6557\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4.0856 - accuracy: 0.5692\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.1647 - accuracy: 0.7581\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.8203 - accuracy: 0.7895\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 7.5826 - accuracy: 0.6207\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 11.4201 - accuracy: 0.3390\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.5217 - accuracy: 0.5000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.6652 - accuracy: 0.6250\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.8615 - accuracy: 0.6364\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.4892 - accuracy: 0.6154\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.4625 - accuracy: 0.5152\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 7.0458 - accuracy: 0.5000\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 6.9794 - accuracy: 0.6892\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5.2588 - accuracy: 0.6438\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.0560 - accuracy: 0.7639\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7553 - accuracy: 0.8169\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 8.3574 - accuracy: 0.6341\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2.7354 - accuracy: 0.7077\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.9231 - accuracy: 0.7867\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2981 - accuracy: 0.8571\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.6051 - accuracy: 0.5366\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 6.4359 - accuracy: 0.4684\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.0863 - accuracy: 0.7368\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1901 - accuracy: 0.9610\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3.1176 - accuracy: 0.5072\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.9994 - accuracy: 0.5844\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5731 - accuracy: 0.9571\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.2391 - accuracy: 0.7377\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.7492 - accuracy: 0.6087\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.8323 - accuracy: 0.6719\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.8226 - accuracy: 0.7213\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.2714 - accuracy: 0.7231\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1943 - accuracy: 0.6452\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4689 - accuracy: 0.6034\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 11.1182 - accuracy: 0.4915\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1810 - accuracy: 0.9844\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.7935 - accuracy: 0.8750\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.9247 - accuracy: 0.6515\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 10.1400 - accuracy: 0.5846\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4.6183 - accuracy: 0.7121\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 10.5039 - accuracy: 0.5270\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 6.6520 - accuracy: 0.7432\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.9717 - accuracy: 0.8630\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9232 - accuracy: 0.8750\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3.0734 - accuracy: 0.8169\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.9593 - accuracy: 0.6951\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.9692\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5.6467 - accuracy: 0.7467\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.1510 - accuracy: 0.7143\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3.8606 - accuracy: 0.7561\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.4961 - accuracy: 0.9114\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.8089 - accuracy: 0.8816\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 8.4897 - accuracy: 0.7013\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1944 - accuracy: 0.9143\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.8340 - accuracy: 0.5574\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.3001 - accuracy: 0.7391\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.7104 - accuracy: 0.5469\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.5081 - accuracy: 0.7213\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.8526 - accuracy: 0.7231\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.6780 - accuracy: 0.6129\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.8331 - accuracy: 0.7193\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 8.4473 - accuracy: 0.4655\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 8.6187 - accuracy: 0.4407\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0408 - accuracy: 0.7031\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.6114 - accuracy: 0.7656\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.9966 - accuracy: 0.6667\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.2509 - accuracy: 0.5846\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4.8723 - accuracy: 0.6970\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 7.2897 - accuracy: 0.5946\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 6.2569 - accuracy: 0.6081\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.6331 - accuracy: 0.8493\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8750\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3.2653 - accuracy: 0.8451\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.8678 - accuracy: 0.6829\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.8923\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.2211 - accuracy: 0.6800\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.0164 - accuracy: 0.8052\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.4201 - accuracy: 0.6098\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.9677 - accuracy: 0.8228\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.0106 - accuracy: 0.7500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 5.6806 - accuracy: 0.6883\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9565\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "sub_num = 30\n",
    "acc = np.zeros(shape=(sub_num,sub_num))\n",
    "conf_mat = np.zeros(shape=(sub_num,sub_num, NUM_CLASSES, NUM_CLASSES))\n",
    "\n",
    "for i in range(sub_num):\n",
    "    for j in range(sub_num):\n",
    "        x_test = sub_data[j]['data_x_test']\n",
    "        y_test = tf.one_hot(sub_data[j]['data_y_test'], NUM_CLASSES)\n",
    "        _, acc[i][j] = classifiers[i].evaluate(x_test, y_test, batch_size=4)\n",
    "        y_test_pred = classifiers[i].predict(x_test)\n",
    "        conf_mat[i][j] = confusion_matrix(y_test.numpy().argmax(axis=1), y_test_pred.argmax(axis=1))\n",
    "\n",
    "\n",
    "save_path = data_path + 'notransfer_acc.npy'\n",
    "np.save(save_path, acc)\n",
    "save_path = data_path + 'notransfer_conf_mat.npy'\n",
    "np.save(save_path, conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "colab_type": "code",
    "id": "wx8c68wuEeM2",
    "outputId": "1f8b5a69-24c9-42ce-bcc7-85f2666080db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.559322</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.831169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.914286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.753247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.465753</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.415584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.231707</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.506494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.506329</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.415584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.589041</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.532468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>0.597403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.353659</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.376623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.890411</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.779221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.288136</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.779221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.870130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.261538</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.402597</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.835616</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.584416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2   ...        27        28        29\n",
       "0   1.000000  0.721311  0.840580  ...  0.701299  0.869565  0.831169\n",
       "1   0.914286  1.000000  0.797101  ...  0.727273  0.507246  0.675325\n",
       "2   0.885714  0.639344  1.000000  ...  0.753247  0.623188  0.753247\n",
       "3   0.342857  0.327869  0.492754  ...  0.272727  0.579710  0.415584\n",
       "4   0.600000  0.557377  0.652174  ...  0.337662  0.753623  0.506494\n",
       "5   0.728571  0.606557  0.811594  ...  0.571429  0.840580  0.727273\n",
       "6   0.442857  0.475410  0.608696  ...  0.532468  0.434783  0.415584\n",
       "7   0.700000  0.688525  0.884058  ...  0.714286  0.681159  0.649351\n",
       "8   0.700000  0.557377  0.623188  ...  0.636364  0.710145  0.649351\n",
       "9   0.757143  0.836066  0.333333  ...  0.636364  0.840580  0.532468\n",
       "10  0.871429  0.754098  0.840580  ...  0.636364  0.956522  0.740260\n",
       "11  0.657143  0.491803  0.811594  ...  0.636364  0.797101  0.636364\n",
       "12  0.800000  0.836066  0.942029  ...  0.688312  0.724638  0.571429\n",
       "13  0.542857  0.852459  0.724638  ...  0.649351  0.449275  0.597403\n",
       "14  0.885714  0.606557  0.898551  ...  0.675325  0.797101  0.805195\n",
       "15  0.400000  0.639344  0.724638  ...  0.467532  0.333333  0.363636\n",
       "16  0.400000  0.737705  0.826087  ...  0.571429  0.333333  0.376623\n",
       "17  0.885714  0.737705  0.681159  ...  0.623377  0.782609  0.766234\n",
       "18  0.900000  0.737705  0.768116  ...  0.558442  0.840580  0.857143\n",
       "19  1.000000  0.688525  0.927536  ...  0.779221  0.724638  0.779221\n",
       "20  0.728571  0.770492  0.768116  ...  0.688312  0.637681  0.688312\n",
       "21  0.671429  0.573770  0.710145  ...  0.662338  0.884058  0.779221\n",
       "22  0.828571  0.721311  0.753623  ...  0.701299  0.927536  0.740260\n",
       "23  0.828571  0.721311  0.768116  ...  0.675325  0.811594  0.766234\n",
       "24  0.957143  0.737705  0.913043  ...  0.766234  0.739130  0.870130\n",
       "25  0.471429  0.508197  0.550725  ...  0.402597  0.884058  0.610390\n",
       "26  0.914286  0.901639  0.898551  ...  0.714286  0.855072  0.818182\n",
       "27  0.642857  0.885246  0.739130  ...  0.961039  0.507246  0.584416\n",
       "28  0.957143  0.737705  0.608696  ...  0.701299  1.000000  1.000000\n",
       "29  0.914286  0.557377  0.739130  ...  0.688312  0.956522  1.000000\n",
       "\n",
       "[30 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = pd.DataFrame(acc)\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "1kus4aHTIy-l",
    "outputId": "af9aca45-63d3-4596-9d4b-409c419a15b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.728571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.432432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.364865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         5         10        15\n",
       "0   1.000000  0.815385  0.859375  0.594595\n",
       "5   0.728571  1.000000  0.921875  0.432432\n",
       "10  0.871429  0.907692  1.000000  0.364865\n",
       "15  0.400000  0.384615  0.187500  1.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df.iloc[[0,5,10,15],[0,5,10,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wvZVitw9J9RQ",
    "outputId": "12f2327a-4826-40f9-aea6-3e07b52c9a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of (0,5):\n",
      "      0    1     2    3     4     5\n",
      "0  11.0  0.0   0.0  0.0   0.0   0.0\n",
      "1   9.0  0.0   1.0  0.0   0.0   0.0\n",
      "2   0.0  0.0  10.0  0.0   0.0   0.0\n",
      "3   0.0  0.0   0.0  9.0   2.0   0.0\n",
      "4   0.0  0.0   0.0  0.0  12.0   0.0\n",
      "5   0.0  0.0   0.0  0.0   0.0  11.0\n",
      "Confusion matrix of (0,10):\n",
      "     0    1    2     3    4     5\n",
      "0  8.0  4.0  0.0   0.0  0.0   0.0\n",
      "1  1.0  7.0  3.0   0.0  0.0   0.0\n",
      "2  0.0  0.0  9.0   0.0  0.0   0.0\n",
      "3  0.0  0.0  0.0  11.0  0.0   0.0\n",
      "4  0.0  0.0  0.0   1.0  8.0   0.0\n",
      "5  0.0  0.0  0.0   0.0  0.0  12.0\n",
      "Confusion matrix of (0,15):\n",
      "     0    1     2    3     4     5\n",
      "0  9.0  0.0   1.0  0.0   0.0   0.0\n",
      "1  5.0  0.0   4.0  0.0   0.0   1.0\n",
      "2  0.0  0.0  10.0  0.0   0.0   0.0\n",
      "3  0.0  0.0   0.0  2.0  12.0   0.0\n",
      "4  1.0  0.0   0.0  6.0   9.0   0.0\n",
      "5  0.0  0.0   0.0  0.0   0.0  14.0\n",
      "Confusion matrix of (5,0):\n",
      "      0    1    2    3    4    5\n",
      "0  12.0  7.0  0.0  0.0  0.0  0.0\n",
      "1   2.0  8.0  1.0  0.0  0.0  0.0\n",
      "2   0.0  3.0  7.0  0.0  0.0  0.0\n",
      "3   0.0  0.0  0.0  9.0  0.0  0.0\n",
      "4   3.0  0.0  0.0  0.0  8.0  0.0\n",
      "5   0.0  0.0  0.0  3.0  0.0  7.0\n",
      "Confusion matrix of (5,10):\n",
      "      0     1    2    3    4     5\n",
      "0  12.0   0.0  0.0  0.0  0.0   0.0\n",
      "1   1.0  10.0  0.0  0.0  0.0   0.0\n",
      "2   0.0   1.0  8.0  0.0  0.0   0.0\n",
      "3   0.0   0.0  0.0  8.0  0.0   3.0\n",
      "4   0.0   0.0  0.0  0.0  9.0   0.0\n",
      "5   0.0   0.0  0.0  0.0  0.0  12.0\n",
      "Confusion matrix of (5,15):\n",
      "     0    1     2    3    4    5\n",
      "0  2.0  7.0   0.0  0.0  0.0  1.0\n",
      "1  0.0  1.0   7.0  0.0  0.0  2.0\n",
      "2  0.0  0.0  10.0  0.0  0.0  0.0\n",
      "3  0.0  0.0   0.0  5.0  9.0  0.0\n",
      "4  3.0  0.0   0.0  6.0  7.0  0.0\n",
      "5  7.0  0.0   0.0  0.0  0.0  7.0\n",
      "Confusion matrix of (10,0):\n",
      "      0     1    2    3     4    5\n",
      "0  15.0   4.0  0.0  0.0   0.0  0.0\n",
      "1   0.0  11.0  0.0  0.0   0.0  0.0\n",
      "2   1.0   0.0  9.0  0.0   0.0  0.0\n",
      "3   0.0   0.0  0.0  9.0   0.0  0.0\n",
      "4   0.0   0.0  0.0  0.0  11.0  0.0\n",
      "5   3.0   1.0  0.0  0.0   0.0  6.0\n",
      "Confusion matrix of (10,5):\n",
      "     0     1     2    3     4     5\n",
      "0  8.0   0.0   0.0  0.0   3.0   0.0\n",
      "1  0.0  10.0   0.0  0.0   0.0   0.0\n",
      "2  0.0   0.0  10.0  0.0   0.0   0.0\n",
      "3  0.0   0.0   0.0  8.0   3.0   0.0\n",
      "4  0.0   0.0   0.0  0.0  12.0   0.0\n",
      "5  0.0   0.0   0.0  0.0   0.0  11.0\n",
      "Confusion matrix of (10,15):\n",
      "     0    1    2    3     4    5\n",
      "0  1.0  9.0  0.0  0.0   0.0  0.0\n",
      "1  1.0  6.0  3.0  0.0   0.0  0.0\n",
      "2  2.0  2.0  6.0  0.0   0.0  0.0\n",
      "3  0.0  0.0  0.0  1.0  13.0  0.0\n",
      "4  7.0  0.0  0.0  3.0   6.0  0.0\n",
      "5  7.0  0.0  0.0  0.0   0.0  7.0\n",
      "Confusion matrix of (15,0):\n",
      "     0    1     2    3    4    5\n",
      "0  5.0  0.0  14.0  0.0  0.0  0.0\n",
      "1  1.0  0.0  10.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  10.0  0.0  0.0  0.0\n",
      "3  0.0  0.0   0.0  4.0  0.0  5.0\n",
      "4  4.0  0.0   0.0  6.0  1.0  0.0\n",
      "5  0.0  2.0   0.0  0.0  0.0  8.0\n",
      "Confusion matrix of (15,5):\n",
      "     0    1     2     3    4    5\n",
      "0  0.0  0.0  11.0   0.0  0.0  0.0\n",
      "1  0.0  0.0  10.0   0.0  0.0  0.0\n",
      "2  0.0  0.0  10.0   0.0  0.0  0.0\n",
      "3  0.0  0.0   0.0   8.0  1.0  2.0\n",
      "4  0.0  0.0   0.0  10.0  2.0  0.0\n",
      "5  0.0  4.0   2.0   0.0  0.0  5.0\n",
      "Confusion matrix of (15,10):\n",
      "     0    1     2    3    4    5\n",
      "0  0.0  0.0   8.0  0.0  0.0  4.0\n",
      "1  0.0  0.0  11.0  0.0  0.0  0.0\n",
      "2  0.0  0.0   9.0  0.0  0.0  0.0\n",
      "3  3.0  0.0   0.0  3.0  0.0  5.0\n",
      "4  0.0  0.0   0.0  8.0  0.0  1.0\n",
      "5  0.0  9.0   3.0  0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "for i in [0,5,10,15]:\n",
    "    for j in [0,5,10,15]:\n",
    "        if i == j:\n",
    "            continue\n",
    "        print(\"Confusion matrix of (%d,%d):\" % (i,j))\n",
    "        print(pd.DataFrame(conf_mat[i][j]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "har-uda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
